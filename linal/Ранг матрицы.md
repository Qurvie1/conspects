Пусть есть k матриц размером m x n $A_1, A_2, ..., A_k$
Тогда эта система матриц называется линейно независимой, если:
$\alpha_1A_1 + \alpha_2A_2 + ... \alpha_kA_k = 0 => \alpha_i = 0 \ \forall i$

Линейно зависимой, если существует набор альф:
$\exists \alpha_1, \alpha_2, ..., \alpha_k$
$\alpha_1^2 + \alpha_2^2 + ... > 0$
$\alpha_1A_1 + ... + \alpha_kA_k = 0$
##### **Теорема: система линейно зависима тогда и только тогда, когда найдётся матрица, которая является линейной комбинацией других (раскладывается иными словами)**
Если у нас подсистема матриц линейно зависима, то и вся система линейно зависима
Рассмотрим единичную матрицу: её строки и столбцы линейно независимы
Какой бы столбец высоты n мы не взяли - он линейная комбинация столбцов единичной матрицы.

Аналогично про строки (идейно: мы типа раскладываем по единичкам, то есть столбец из единичек - это все столбцы единичной матрицы сложенные и прочее)

Рассмотрим матрицу AB
j-й столбец матрицы - линейная комбинация столбоцов матрицы А с коэф. j-го столбца B
Возьмём 2 столбца a, b, тогда:
$a^TAb = a^TBb => A = B$

Идейно - просто берём столбец с единичной в строке i и столбец b с единичкой в j, тогда в точности получим элемент $a_{ij}$ и $b_{ij}$ соответственно, тогда если это верно для всех столбцов a, b, тогда матрицы совпадают поэлементно (равны).

Возьмём матрицу А и поймём, когда её набор строк линейно зависим.
Строки линейно зависимы, если существует строка c ненулевая такая, что:
cA = 0 (аналогично со столбцами, но справа)

Если А линейно зависима, то и AB линейно зависимы (квадратные матрицы одного порядка)
$c(AB) = (cA)B = 0B = 0$
При элементарных преобразованиях линейная зависимость не меняется (как и независимость)

Докажем для строк
Пусть набор строк линейно независим, и мы сложим строки:
$a_1, a_2, ... -> a_1 + a_2, a_2, ...$

Но тогда, если набор = 0, то по условию линейной независимости, что все альфы = 0 то есть этот набор тоже линейно независим

Как доказать для линейной зависимости? От противного, то есть если получили линейно независимй набор, то обратные операции утверждают, то из ЛНЗ получили ЛЗ, чего не может быть по доказанному.

Далее, пусть строки линейно зависимы, сделаем элементарные преобразования столбцов.
##### Теорема: если рассмотрим элементарные преобразования столбцов, то сохранятся линейные зависимости строк (то есть с теми же коэфами)
По опр ЛЗ:
$cA = 0$
элементарные преобразования $A -> AS$
$c(AS) = (cA)S = 0$
то есть мы берём с теми же коэффициентами (в строке c) они всё ещё обнуляют матрицу.

Теперь поработаем с детерминантом
$det A \ne 0$

A -> (если матрица А невырождена, при помощи эл. преобразований ТОЛЬКО СТРОК) можно превратить её в единичную -> E

Аналогично для столбцов (если рассмотреть транспонированную)
Тогда детерминант не 0 тогда и только тогда, когда и строки, и столбцы линейно независимы.
det A != 0

Тогда можно представить столбец высоты n в виде линейной комбинации столбов А единственным образом.

(достаточно очевидно, если просто расписать умножение А на какой-то столбец, тогда у нас первый столбец будет идти с коэффициентом $b_{11}$, потом второй с $b_{12}$
Ax = d
Найдём этот столбец x
По опр обратной матрицы:
$AA^{-1}d = d => A(A^{-1}d) = d => x = A^{-1}d$


**Пусть строка c раскладывается по строкам $a_1, ..., a_k$, тогда разложение единственно тогда и только тогда, когда набор строк ЛНЗ**
Переходим теперь к рангу матрицы

Пусть в матрице А нашлась система из r линейно независимых строк. И для любого k > r система из k строк ЛЗ или не существует.
Тогда r - строчный ранг (обозначим $r_1(A)$)
Эти строки - базисные

Любая строка матрицы раскладывается в линейную комбинацию базисных:
1) Если она базисная, тогда берём эту строку с коэффом 1, другие с 0, разложили
2) Не базисная, тогда возьмём эту строку и базисные - он ЛЗ, по опр строчного ранга, тогда коэф. при этой строке не ноль, отсюда можно выразить его.
Тогда это разложение ещё и единственно по прошлому.

Введём столбцовый ранг (аналогично)
Оба этих ранга не меняются при элементарных преобразованиях

Рассмотрим подматрицу (элементы не обязательно рядом кстати), тогда ранг подматрицы не превосходит ранг матрицы.

Очевидно следует, что если набор строк исходных матриц линейно зависим, то и для подматрицы это тоже будет верно (эти строки тоже будут линейно зависимы)

Теорема: n + 1 столбец высоты n линейно зависимый
Обозначим столбцы $b_1, b_2, ..., b_{n+1}$

Рассмотрим первые n столбцов, если они ЛЗ, то теорема доказана.

Если они ЛНЗ, то из них можно составить невырожденную матрицу и тогда любой столбец может быть выражен как линейная комбинация

Теперь докажем, что для любой матрицы A строчный ранг равен столбцовому
$r_1(A) <= m$
Выделим базисные строки и из этих базисных строк выделим базисные столбцы (то есть возьмём элементы на пересечении базисных строк и базисных столбцов)

Рассмотрим небазисную строку и вычтем из неё комбинацию базисных, обнуляющих её (аналогично со столбцами)

Что тогда происходит - базисные столбцы останутся базисными (сохраняются линейные зависимости)

Тогда количество базисных столбцов не превосходит высоту столбца (а она $r_1$ на пересечениях), так как если больше, то будет линейная зависимость по доказанной теореме.
Те же рассуждения для столбцов дадут обратное
Отсюда получаем, что ранги равны.

Тогда введём понятие ранг матрицы
$Rg A = r_1(A) = r_2(A) = rg A^T$
Что же мы на самом деле доказали:
Мы получили в пересечении базисных строк и столбцов матрицу Rg A x Rg A
И она невырожденная 

То есть любая матрица порядка больше Rg A - её детерминант равен 0.
Тогда есть понятие минорного ранга - порядок максимальный невырожденной подматрицы (и он тогда равен Rg A).
